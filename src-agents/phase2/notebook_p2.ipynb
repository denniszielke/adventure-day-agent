{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase2 - RAG\n",
    "\n",
    "If not already done run this in the top level folder:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector search index\n",
    "\n",
    "Create your search index schema and vector search configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex\n",
    "\n",
    ")\n",
    "\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_AI_SEARCH_KEY\"]) if len(os.environ[\"AZURE_AI_SEARCH_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "\n",
    "index_name = \"movies-semantic-index\"\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# Create a search index with the fields and a vector field which we will fill with a vector based on the overview field\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"genre\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"year\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"rating\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"plot\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure the semantic search configuration to prefer title and tagline fields over overview\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"movies-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"genre\")],\n",
    "        content_fields=[SemanticField(field_name=\"plot\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_or_false = \"true_or_false\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom data\n",
    "Here's how you load custom vector data by means of an embedding model and then query it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "# use an embeddingsmodel to create embeddings\n",
    "def get_embedding(text, model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# 1. define function to parse csv row and create embedding for overview text\n",
    "def parseMovie(movie):\n",
    "    print(movie)\n",
    "    return dict([\n",
    "        (\"id\", str(movie[\"movie_id\"])),\n",
    "        (\"genre\", movie[\"movie_genre\"]),\n",
    "        (\"title\", movie[\"movie_title\"]),\n",
    "        (\"year\", str(movie[\"movie_year\"])),\n",
    "        (\"rating\", str(movie[\"movie_rating\"])),\n",
    "        (\"plot\", movie[\"movie_plot\"]),\n",
    "        (\"vector\", get_embedding(movie[\"movie_plot\"]))\n",
    "    ])\n",
    "\n",
    "# 2. load movies from csv\n",
    "movies = []\n",
    "with open('./movies.json') as json_data:\n",
    "    moviesJson = json.load(json_data)\n",
    "    line_count = 0\n",
    "    for movieJson in moviesJson:\n",
    "        movieEmbedding = parseMovie(movieJson)\n",
    "        movies.append(movieEmbedding)\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "print('Loaded %s movies.' % len(movies))\n",
    "\n",
    "\n",
    "# 3. upload documents to vector store\n",
    "search_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "result = search_client.upload_documents(movies)\n",
    "print(f\"Successfully loaded {len(movies)} movies into Azure AI Search index.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query index and create a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")\n",
    "\n",
    "index_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "question = \"Tell me about the latest Ant Man movie. When was it released?\"\n",
    "\n",
    "# create a vectorized query based on the question\n",
    "vector = VectorizedQuery(vector=get_embedding(question), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "\n",
    "# create search client to retrieve movies from the vector store\n",
    "found_docs = list(search_client.search(\n",
    "    search_text=None,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"movies-semantic-config\",\n",
    "    vector_queries=[vector],\n",
    "    select=[\"title\", \"genre\", \"plot\"],\n",
    "    top=5\n",
    "))\n",
    "\n",
    "# print the found documents and the field that were selected\n",
    "for doc in found_docs:\n",
    "    print(\"Movie: {}\".format(doc[\"title\"]))\n",
    "    print(\"Genre: {}\".format(doc[\"genre\"]))\n",
    "    print(\"----------\")\n",
    "\n",
    "\n",
    "found_docs_as_text = \" \"\n",
    "for elem in enumerate(found_docs, start=1):    \n",
    "    found_docs_as_text += \" \"+ \"Movie Title: {}\".format(doc[\"title\"]) +\" \"+ \"Movie story: {}\".format(doc[\"plot\"])\n",
    "\n",
    "# augment the question with the found documents and ask the LLM to generate a response\n",
    "system_prompt = \"You are an assistant to the user, you are given some context below, please answer the query of the user with as detail as possible\"\n",
    "\n",
    "parameters = [system_prompt, ' Context:', found_docs_as_text , ' Question:', question]\n",
    "joined_parameters = ''.join(parameters)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : joined_parameters}],\n",
    "    )\n",
    "\n",
    "print (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    \"\"\"\n",
    "    Ask a question\n",
    "    \"\"\"\n",
    "    \n",
    "    answer = \"I dont know\"\n",
    "\n",
    "    #####\\n\",\n",
    "    # implement rag flow here\\n\",\n",
    "    ######\\n\",\n",
    "   \n",
    "    \n",
    "    print('Answer:', answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ask = Ask(question=\"How many actors were featured in The Smonger Games?\", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "print('Answer:', answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase2 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
