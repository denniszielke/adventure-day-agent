{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Function Calling\n",
    "\n",
    "## About this phase\n",
    "In this challenge you have to make sure, that your API is able to answer questions, that neither the model knows, nor are the answers hidden in your custom data. But you can make your model aware of a bunch of APIs that can be used to call the APIs. \n",
    "So go, make the model aware of the APIs and build an application that call the APIs whenever required!\n",
    "\n",
    "\n",
    "If not already done run this in the top level folder:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_or_false = \"true_or_false\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "smoorghApi = \"https://.northeurope.azurecontainerapps.io/\"\n",
    "\n",
    "def get_movie_rating(title):\n",
    "    try:\n",
    "        response = requests.get(f\"{smoorghApi}/rating/{title}\")\n",
    "        print('The api response for rating is:', response.text)\n",
    "        return response.text\n",
    "    \n",
    "    except:\n",
    "        return \"Sorry, I couldn't find a rating for that movie.\"\n",
    "\n",
    "def get_movie_year(title):\n",
    "    try:\n",
    "        response = requests.get(f\"{smoorghApi}/year/{title}\")\n",
    "        print('The api response for year is:', response.text)\n",
    "        return response.text\n",
    "\n",
    "    except:\n",
    "        return \"Sorry, I couldn't find a year for that movie.\"\n",
    "    \n",
    "def get_movie_actor(title):\n",
    "    try:\n",
    "        response = requests.get(f\"{smoorghApi}/actor/{title}\")\n",
    "        print('The api response for actor is:', response.text)\n",
    "        return response.text\n",
    "\n",
    "    except:\n",
    "        return \"Sorry, I couldn't find an actor for that movie.\"\n",
    "    \n",
    "def get_movie_location(title):\n",
    "    try:\n",
    "        response = requests.get(f\"{smoorghApi}/location/{title}\")\n",
    "        print('The api response for location is:', response.text)\n",
    "        return response.text\n",
    "\n",
    "    except:\n",
    "        return \"Sorry, I couldn't find a location for that movie.\"\n",
    "\n",
    "def get_movie_genre(title):\n",
    "    try:\n",
    "        response = requests.get(f\"{smoorghApi}/genre/{title}\")\n",
    "        print('The api response for genre is:', response.text)\n",
    "        return response.text\n",
    "\n",
    "    except:\n",
    "        return \"Sorry, I couldn't find a genre for that movie.\"\n",
    "\n",
    "print(get_movie_rating(\"The Lost Planet\"))\n",
    "\n",
    "print(get_movie_year(\"The Lost Planet\"))\n",
    "\n",
    "print(get_movie_actor(\"The Lost Planet\"))\n",
    "\n",
    "print(get_movie_location(\"The Lost Planet\"))\n",
    "\n",
    "print(get_movie_genre(\"The Lost Planet\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the model aware of the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_movie_rating\",\n",
    "                \"description\": \"Gets the rating of a movie\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"title\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The movie name. The movie name should be a string without quotation marks.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"title\"],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "         {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_movie_location\",\n",
    "                \"description\": \"Gets the location of a movie\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"title\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The movie name. The movie name should be a string without quotation marks.\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"title\"],\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ]   \n",
    "available_functions = {\n",
    "            \"get_movie_rating\": get_movie_rating,\n",
    "            \"get_movie_location\": get_movie_location        \n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    \"\"\"\n",
    "    Ask a question\n",
    "    \"\"\"\n",
    "    \n",
    "    question = ask.question\n",
    "    messages= [{\"role\" : \"assistant\", \"content\" : question}\n",
    "               , { \"role\" : \"system\", \"content\" : \"Answer the question of the user and use the tools available to you.\"}\n",
    "               ]\n",
    "    first_response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = messages,\n",
    "        tools = functions,\n",
    "        tool_choice = \"auto\",\n",
    "    )\n",
    "\n",
    "    print(first_response)\n",
    "    response_message = first_response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "\n",
    "     # Step 2: check if GPT wanted to call a function\n",
    "    if tool_calls:\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(tool_calls)\n",
    "        print()\n",
    "    \n",
    "        # Step 3: call the function\n",
    "        messages.append(response_message)\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            # verify function exists\n",
    "            if function_name not in available_functions:\n",
    "                return \"Function \" + function_name + \" does not exist\"\n",
    "            else:\n",
    "                print(\"Calling function: \" + function_name)\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            print(function_args)\n",
    "            function_response = function_to_call(**function_args)\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            ) \n",
    "            print(\"Addding this message to the next prompt:\") \n",
    "            print (messages)\n",
    "            \n",
    "             # extend conversation with function response\n",
    "            second_response = client.chat.completions.create(\n",
    "                model = model_name,\n",
    "                messages = messages)  # get a new response from the model where it can see the function response\n",
    "            \n",
    "            print(\"second_response\")\n",
    "            \n",
    "            return second_response.choices[0].message.content\n",
    "            \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ask = Ask(question=\"Which country does 'Hobbiton: The Heist of the Silver Dragon' take place in?\", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "print('Answer:', answer )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase3 $AZURE_ENV_NAME\n",
    "```\n",
    "Make sure to provide the URL of your endpoint in the team portal!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
