{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Setting everything up\n",
    "\n",
    "Open this repository in a GitHub Codespace.\n",
    "Before you start with anything else, make sure you setup the infrastructure required. Follow the readme file in the root folder to do this!\n",
    "\n",
    "To start with Phase 1, if not already done run this in the top level folder:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://cog-45xex7bgir6oe.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if stuff works in general, you can run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spending quality time with loved ones. Whether it's having a deep conversation, sharing a meal, or enjoying a fun activity together, the connection and joy it brings are unmatched. What about you?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = model_name,    \n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_or_false = \"true_or_false\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    # \"\"\"\n",
    "    # # Ask a question\n",
    "    # \"\"\"\n",
    "\n",
    "    # Send a completion call to generate an answer\n",
    "    print('Sending a request to openai')\n",
    "    \n",
    "    start_phrase =  ask.question\n",
    "    response: openai.types.chat.chat_completion.ChatCompletion = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : start_phrase}, \n",
    "                     { \"role\" : \"system\", \"content\" : \"Answer the question solely with the answer. For estimation questions use number symbols. Format the answer to remove all punctuation:\"}]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    print(response)\n",
    "    answer = Answer(answer=response.choices[0].message.content)\n",
    "    answer.correlationToken = ask.correlationToken\n",
    "    answer.promptTokensUsed = response.usage.prompt_tokens\n",
    "    answer.completionTokensUsed = response.usage.completion_tokens\n",
    "    \n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a request to openai\n",
      "Green\n",
      "ChatCompletion(id='chatcmpl-A8OdYTCyZcZK7vuTuBEFI7wNYLL0D', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Green', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726564692, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=1, prompt_tokens=51, total_tokens=52), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='Green' correlationToken=None promptTokensUsed=51 completionTokensUsed=1\n",
      "Sending a request to openai\n",
      "The Wizard of Oz\n",
      "ChatCompletion(id='chatcmpl-A8OdYGUW1e9bz10eyLDHVGLOjo1jB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Wizard of Oz', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726564692, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=4, prompt_tokens=78, total_tokens=82), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='The Wizard of Oz' correlationToken=None promptTokensUsed=78 completionTokensUsed=4\n",
      "Sending a request to openai\n",
      "False\n",
      "ChatCompletion(id='chatcmpl-A8OdZlfd65mSR0QwI5w9KldDQicct', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='False', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726564693, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=1, prompt_tokens=49, total_tokens=50), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='False' correlationToken=None promptTokensUsed=49 completionTokensUsed=1\n",
      "Sending a request to openai\n",
      "3\n",
      "ChatCompletion(id='chatcmpl-A8OdZfDQiYprFZ8pWbZJQzGhzUTNl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='3', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726564693, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=1, prompt_tokens=53, total_tokens=54), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='3' correlationToken=None promptTokensUsed=53 completionTokensUsed=1\n",
      "Sending a request to openai\n",
      "Robert Downey Jr\n",
      "ChatCompletion(id='chatcmpl-A8OdZ9mWclLEidbPorVwb8GdwrqoW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Robert Downey Jr', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726564693, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=4, prompt_tokens=62, total_tokens=66), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='Robert Downey Jr' correlationToken=None promptTokensUsed=62 completionTokensUsed=4\n"
     ]
    }
   ],
   "source": [
    "ask0 = Ask(question=\"Which of the following is a color? a. Tree b. Flower c. Green\", type=QuestionType.multiple_choice)\n",
    "answer0 = await ask_question(ask0)\n",
    "print('Answer:', answer0)\n",
    "\n",
    "ask1 = Ask(question=\"Which movie features a plot where a young girl named Dorothy is transported to a magical land via a tornado? 1) Cinderella 2) The Wizard of Oz 3) Alice in Wonderland 4) The Little Mermaid\", type=QuestionType.multiple_choice)\n",
    "answer1 = await ask_question(ask1)\n",
    "print('Answer:', answer1)\n",
    "\n",
    "ask2 = Ask(question=\"Is Yoda a character from the Star Trek universe: True or False?\", type=QuestionType.true_or_false)\n",
    "answer2 = await ask_question(ask2)\n",
    "print('Answer:', answer2)\n",
    "\n",
    "ask3 = Ask(question=\"How many movies are there in 'The Lord of the Rings' trilogy directed by Peter Jackson?\", type=QuestionType.estimation)\n",
    "answer3 = await ask_question(ask3)\n",
    "print('Answer:', answer3)\n",
    "\n",
    "ask4 = Ask(question=\"Who is the actor behind iron man?  1. Bill Gates, 2. Robert Downey Jr, 3. Jeff Bezos\", type=QuestionType.multiple_choice)\n",
    "answer4 = await ask_question(ask4)\n",
    "print('Answer:', answer4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Questions\n",
    "Sample Questions could look like this. Make sure your answer exactly  matches the required answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "{\n",
    "    \"id\": 3,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"Which movie features a plot where a young girl named Dorothy is transported to a magical land via a tornado? 1) Cinderella 2) The Wizard of Oz 3) Alice in Wonderland 4) The Little Mermaid\",\n",
    "    \"answer\": \"The Wizard of Oz\",\n",
    "    \"type\": \"multiple_choice\"\n",
    "},\n",
    "{\n",
    "    \"id\": 4,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"Is Yoda a character from the Star Trek universe: True or False?\",\n",
    "    \"answer\": false,\n",
    "    \"type\": \"true_or_false\"\n",
    "},\n",
    "{\n",
    "    \"id\": 5,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"How many movies are there in 'The Lord of the Rings' trilogy directed by Peter Jackson?\",\n",
    "    \"answer\": 3,\n",
    "    \"type\": \"estimation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). \n",
    "You can test your app locally using uvicorn. (See Readme.md for details.)\n",
    "\n",
    "Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase1 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
